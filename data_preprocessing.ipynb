{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbf0e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loaded 12530806 interactions from big matrix\n",
      "Loaded 4676570 interactions from small matrix\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import ast\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MultiLabelBinarizer\n",
    "import pickle\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization parameters\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Create directories for outputs\n",
    "os.makedirs('outputs/figures', exist_ok=True)\n",
    "os.makedirs('outputs/models', exist_ok=True)\n",
    "os.makedirs('outputs/data', exist_ok=True)\n",
    "os.makedirs('outputs/data/processed', exist_ok=True)\n",
    "\n",
    "# Define dataset path\n",
    "DATA_PATH = \"KuaiRec/data/\"\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "big_matrix = pd.read_csv(f\"{DATA_PATH}big_matrix.csv\")\n",
    "small_matrix = pd.read_csv(f\"{DATA_PATH}small_matrix.csv\")\n",
    "social_network = pd.read_csv(f\"{DATA_PATH}social_network.csv\")\n",
    "user_features = pd.read_csv(f\"{DATA_PATH}user_features.csv\")\n",
    "item_daily_features = pd.read_csv(f\"{DATA_PATH}item_daily_features.csv\")\n",
    "item_categories = pd.read_csv(f\"{DATA_PATH}item_categories.csv\")\n",
    "\n",
    "print(f\"Loaded {len(big_matrix)} interactions from big matrix\")\n",
    "print(f\"Loaded {len(small_matrix)} interactions from small matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1abb1198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing interaction data...\n",
      "Removed 965819 rows (7.71%)\n",
      "Removed 181992 rows (3.89%)\n",
      "Processing social network data...\n",
      "Processing item categories...\n",
      "\n",
      "Number of unique users: 7176\n",
      "Number of unique videos: 10728\n",
      "Average watch ratio: 0.9466\n",
      "Sparsity: 0.849774\n"
     ]
    }
   ],
   "source": [
    "# Clean and preprocess data\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Clean and preprocess interaction data\"\"\"\n",
    "    initial_size = len(df)\n",
    "    # Remove missing values and duplicates\n",
    "    df = df.dropna().drop_duplicates()\n",
    "    # Remove negative timestamps (invalid data)\n",
    "    df = df[df['timestamp'] > 0]\n",
    "    final_size = len(df)\n",
    "    print(f\"Removed {initial_size - final_size} rows ({(initial_size - final_size)/initial_size:.2%})\")\n",
    "    return df\n",
    "\n",
    "# Process interaction data\n",
    "print(\"Preprocessing interaction data...\")\n",
    "big_matrix = preprocess_data(big_matrix)\n",
    "small_matrix = preprocess_data(small_matrix)\n",
    "\n",
    "# Process social network data\n",
    "print(\"Processing social network data...\")\n",
    "social_network['friend_list'] = social_network['friend_list'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else []\n",
    ")\n",
    "\n",
    "# Process item categories\n",
    "print(\"Processing item categories...\")\n",
    "item_categories['feat'] = item_categories['feat'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else []\n",
    ")\n",
    "\n",
    "# Fill missing values in user and item features\n",
    "user_features.fillna(-1, inplace=True)\n",
    "item_daily_features.fillna(-1, inplace=True)\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nNumber of unique users: {big_matrix['user_id'].nunique()}\")\n",
    "print(f\"Number of unique videos: {big_matrix['video_id'].nunique()}\")\n",
    "print(f\"Average watch ratio: {big_matrix['watch_ratio'].mean():.4f}\")\n",
    "\n",
    "# Calculate sparsity\n",
    "total_possible_interactions = big_matrix['user_id'].nunique() * big_matrix['video_id'].nunique()\n",
    "sparsity = 1 - (len(big_matrix) / total_possible_interactions)\n",
    "print(f\"Sparsity: {sparsity:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a692c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating one-hot encoded category features...\n",
      "Processing item daily features...\n",
      "Processing user features...\n"
     ]
    }
   ],
   "source": [
    "# Process item categories with MultiLabelBinarizer\n",
    "print(\"Creating one-hot encoded category features...\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "item_categories_encoded = pd.DataFrame(\n",
    "    mlb.fit_transform(item_categories['feat']),\n",
    "    columns=[f'category_{i}' for i in mlb.classes_],\n",
    "    index=item_categories['video_id']\n",
    ")\n",
    "\n",
    "# Process item daily features\n",
    "print(\"Processing item daily features...\")\n",
    "# Get the most recent features for each video\n",
    "item_daily_latest = item_daily_features.loc[\n",
    "    item_daily_features.groupby('video_id')['date'].idxmax()\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Select numerical features\n",
    "numerical_features = [\n",
    "    'video_duration', 'video_width', 'video_height', \n",
    "    'play_cnt', 'play_user_num', 'play_duration',\n",
    "    'complete_play_cnt', 'valid_play_cnt', 'long_time_play_cnt',\n",
    "    'show_cnt', 'show_user_num', 'like_cnt', 'comment_cnt',\n",
    "    'share_cnt', 'download_cnt'\n",
    "]\n",
    "\n",
    "# Select categorical features for one-hot encoding\n",
    "categorical_features = ['video_type', 'upload_type', 'visible_status']\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "categorical_encoded = pd.DataFrame(\n",
    "    encoder.fit_transform(item_daily_latest[categorical_features]),\n",
    "    columns=encoder.get_feature_names_out(categorical_features),\n",
    "    index=item_daily_latest.index\n",
    ")\n",
    "\n",
    "# Combine numerical and categorical features\n",
    "item_features_combined = pd.concat([\n",
    "    item_daily_latest[['video_id'] + numerical_features],\n",
    "    categorical_encoded.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Merge with category features\n",
    "item_features_df = pd.merge(\n",
    "    item_features_combined,\n",
    "    item_categories_encoded.reset_index(),\n",
    "    on='video_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Process user features\n",
    "print(\"Processing user features...\")\n",
    "# Select relevant user features\n",
    "user_features_selected = user_features[[\n",
    "    'user_id', 'user_active_degree', 'follow_user_num', 'fans_user_num',\n",
    "    'friend_user_num', 'register_days', 'is_lowactive_period',\n",
    "    'is_live_streamer', 'is_video_author'\n",
    "] + [f'onehot_feat{i}' for i in range(18)]].copy()\n",
    "\n",
    "# Convert categorical features to numeric\n",
    "categorical_user_cols = ['user_active_degree']\n",
    "for col in categorical_user_cols:\n",
    "    user_features_selected[col] = user_features_selected[col].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a83f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed data...\n",
      "Data preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "# Save processed data\n",
    "print(\"Saving processed data...\")\n",
    "big_matrix.to_csv('outputs/data/processed/big_matrix_processed.csv', index=False)\n",
    "small_matrix.to_csv('outputs/data/processed/small_matrix_processed.csv', index=False)\n",
    "item_features_df.to_csv('outputs/data/processed/item_features_processed.csv', index=False)\n",
    "user_features_selected.to_csv('outputs/data/processed/user_features_processed.csv', index=False)\n",
    "\n",
    "print(\"Data preprocessing complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
